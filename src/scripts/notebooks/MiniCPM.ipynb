{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmdeploy import pipeline, TurbomindEngineConfig\n",
    "from lmdeploy.vl import load_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "image_dir = \"AML/66e31d6ee96cd_student_resource_3/student_resource 3/test\"\n",
    "download_dir = \"AML/models\"\n",
    "# Format of the prompt\n",
    "prompt_format = '''Extract the best (only one) item and its unit from the image in the format - \\nValue: <only numbers> \\nUnit: <only alphabets>\n",
    "'''\n",
    "batch_size = 16\n",
    "test = True\n",
    "# CUDA devices\n",
    "device = 0\n",
    "save_dir = \"AML/save_data_minicpm/\"\n",
    "# Counter\n",
    "start = 0\n",
    "\n",
    "file_name = f\"data_{start}.pkl\"\n",
    "# Ensuring appropriate GPU allocation\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device)\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "# Loading the CSV\n",
    "load_path =\"AML/data/test.csv\"\n",
    "df = pd.read_csv(load_path)\n",
    "\n",
    "if not test:\n",
    "    df_train, df = train_test_split(df, test_size=0.08, random_state=1, shuffle=False)\n",
    "\n",
    "# Based on start and end indexes\n",
    "df = df[:min((start+1)*len(df)//4, len(df))][start*len(df)//4:]\n",
    "\n",
    "images = df[\"image_link\"].apply(lambda x: image_dir + \"/\" + x.split(\"/\")[-1]).tolist()\n",
    "prompts = df[\"entity_name\"].apply(lambda x: prompt_format.split(\"item\")[0].strip() + \" \" + ' '.join(x.split(\"_\")) + \" \" + prompt_format.split(\"item\")[1].strip()).tolist()\n",
    "\n",
    "model = \"openbmb/MiniCPM-V-2_6\"\n",
    "# Model pipeline\n",
    "pipe = pipeline(model, backend_config=TurbomindEngineConfig(session_len=None, download_dir=download_dir))\n",
    "\n",
    "# List of responses\n",
    "responses = []\n",
    "count = 0\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    torch.cuda.empty_cache()\n",
    "    # Batching the prompt+images and then processing the batch and get responses\n",
    "    response = pipe([(prompts[i + j], images[i + j]) for j in range(min(batch_size, len(prompts) - i))])\n",
    "    \n",
    "    # Append the responses (adjusting the indexing)\n",
    "    for j in range(min(batch_size, len(prompts) - i)):\n",
    "        # Assuming response[j].text holds the required text, append it\n",
    "        responses.append(response[j].text)\n",
    "    \n",
    "    # Increment counter\n",
    "    count += 1\n",
    "    print(count)\n",
    "\n",
    "# Final save of all responses after the loop finishes\n",
    "with open(save_dir + file_name, \"wb\") as f:\n",
    "    pickle.dump(responses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
